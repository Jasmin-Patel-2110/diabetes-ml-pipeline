{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your datasets\n",
    "pidd_data = pd.read_csv('diabetes.csv')\n",
    "frankfurt_data = pd.read_csv('diabetes_2.csv')\n",
    "\n",
    "# Combine datasets for processing\n",
    "datasets = {\n",
    "    \"PIDD\": pidd_data,\n",
    "    \"Frankfurt\": frankfurt_data\n",
    "}\n",
    "\n",
    "# Imputation methods\n",
    "imputation_methods = ['no_imputation', 'mean', 'median', 'knn', 'random_sample', 'mice']\n",
    "scalers = ['standard', 'minmax']\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(method, X):\n",
    "    \n",
    "    # Identify columns with 0 as missing values, excluding 'Pregnancies'\n",
    "    cols_with_zeros = X.columns[(X == 0).any()]\n",
    "    cols_with_zeros = cols_with_zeros.drop('Pregnancies')\n",
    "    \n",
    "    # Count the number of 0s before imputation\n",
    "    # print(f\"Imputation method: {method}\")\n",
    "    # print(\"Columns to impute (0 values):\", list(cols_with_zeros))\n",
    "    # print(\"Before imputation, number of 0s in columns to impute:\")\n",
    "    # print(X[cols_with_zeros].apply(lambda col: (col == 0).sum()))\n",
    "    \n",
    "    # Convert 0 values to NaN for imputation\n",
    "    X_imputed = X.copy()\n",
    "    X_imputed[cols_with_zeros] = X_imputed[cols_with_zeros].replace(0, np.nan)\n",
    "    \n",
    "    if method == 'mean':\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_imputed[cols_with_zeros] = imputer.fit_transform(X_imputed[cols_with_zeros])\n",
    "    elif method == 'median':\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        X_imputed[cols_with_zeros] = imputer.fit_transform(X_imputed[cols_with_zeros])\n",
    "    elif method == 'knn':\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        X_imputed[cols_with_zeros] = imputer.fit_transform(X_imputed[cols_with_zeros])\n",
    "    elif method == 'random_sample':\n",
    "        for column in cols_with_zeros:\n",
    "            population = X_imputed[column][X_imputed[column] != 0]\n",
    "            if not population.empty:\n",
    "                X_imputed.loc[X_imputed[column].isna(), column] = random.choices(population.tolist(), k=X_imputed[column].isna().sum())\n",
    "            else:\n",
    "                mean_value = X_imputed[column].mean()\n",
    "                X_imputed.loc[X_imputed[column].isna(), column] = mean_value\n",
    "    elif method == 'mice':\n",
    "        imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "        X_imputed[cols_with_zeros] = imputer.fit_transform(X_imputed[cols_with_zeros])\n",
    "    \n",
    "    # Replace NaN back to 0 (optional, based on your need)\n",
    "    X_imputed[cols_with_zeros] = X_imputed[cols_with_zeros].fillna(0)\n",
    "    \n",
    "    # Count the number of 0s after imputation\n",
    "    # print(\"After imputation, number of 0s in columns to impute:\")\n",
    "    # print(X_imputed[cols_with_zeros].apply(lambda col: (col == 0).sum()))\n",
    "    \n",
    "    return X_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare results storage\n",
    "# results_list = []\n",
    "\n",
    "# for dataset_name, dataset in datasets.items():\n",
    "#     X = dataset.drop('Outcome', axis=1)\n",
    "#     y = dataset['Outcome']\n",
    "\n",
    "#     for imputation_method in imputation_methods:\n",
    "#         # Apply imputation\n",
    "#         X_imputed = impute_data(imputation_method, X)\n",
    "\n",
    "#         for scaling_method in scalers:\n",
    "#             # Apply scaling\n",
    "#             if scaling_method == 'standard':\n",
    "#                 scaler = StandardScaler()\n",
    "#                 X_scaled = scaler.fit_transform(X_imputed)\n",
    "#             elif scaling_method == 'minmax':\n",
    "#                 scaler = MinMaxScaler()\n",
    "#                 X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "#             for model_name, model in models.items():\n",
    "#                 try:\n",
    "#                     # Train-test split (70% training, 30% testing)\n",
    "#                     X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#                     # Fit the model\n",
    "#                     model.fit(X_train, y_train)\n",
    "\n",
    "#                     # Make predictions\n",
    "#                     y_pred = model.predict(X_test)\n",
    "\n",
    "#                     # Compute metrics\n",
    "#                     accuracy = accuracy_score(y_test, y_pred)\n",
    "#                     precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "#                     recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "#                     f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "#                     # Store the results\n",
    "#                     results_list.append({\n",
    "#                         'Dataset': dataset_name,\n",
    "#                         'Imputation': imputation_method,\n",
    "#                         'Scaling': scaling_method,\n",
    "#                         'Model': model_name,\n",
    "#                         'Accuracy': accuracy,\n",
    "#                         'Precision': precision,\n",
    "#                         'Recall': recall,\n",
    "#                         'F1-score': f1\n",
    "#                     })\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing {dataset_name} with {imputation_method}, {scaling_method}, {model_name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Imputation</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIDD</td>\n",
       "      <td>no_imputation</td>\n",
       "      <td>standard</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'solver': 'liblinear'}</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.634146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIDD</td>\n",
       "      <td>no_imputation</td>\n",
       "      <td>standard</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.7, 'gamma': 0.5, 'kernel': 'linear'}</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.645963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIDD</td>\n",
       "      <td>no_imputation</td>\n",
       "      <td>standard</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 5, 'wei...</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.573248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIDD</td>\n",
       "      <td>no_imputation</td>\n",
       "      <td>standard</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'min_...</td>\n",
       "      <td>0.731602</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.647727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIDD</td>\n",
       "      <td>no_imputation</td>\n",
       "      <td>standard</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'n_es...</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>mice</td>\n",
       "      <td>minmax</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'solver': 'lbfgs'}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.587678</td>\n",
       "      <td>0.664879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>mice</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.9, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.798333</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.606635</td>\n",
       "      <td>0.679045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>mice</td>\n",
       "      <td>minmax</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 6, 'wei...</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.940909</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.960557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>mice</td>\n",
       "      <td>minmax</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'min_sam...</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.764192</td>\n",
       "      <td>0.829384</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>mice</td>\n",
       "      <td>minmax</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'n_estim...</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.822727</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.839907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset     Imputation   Scaling                Model  \\\n",
       "0         PIDD  no_imputation  standard  Logistic Regression   \n",
       "1         PIDD  no_imputation  standard                  SVM   \n",
       "2         PIDD  no_imputation  standard                  KNN   \n",
       "3         PIDD  no_imputation  standard        Decision Tree   \n",
       "4         PIDD  no_imputation  standard        Random Forest   \n",
       "..         ...            ...       ...                  ...   \n",
       "115  Frankfurt           mice    minmax  Logistic Regression   \n",
       "116  Frankfurt           mice    minmax                  SVM   \n",
       "117  Frankfurt           mice    minmax                  KNN   \n",
       "118  Frankfurt           mice    minmax        Decision Tree   \n",
       "119  Frankfurt           mice    minmax        Random Forest   \n",
       "\n",
       "                                           Best Params  Accuracy  Precision  \\\n",
       "0                              {'solver': 'liblinear'}  0.740260   0.626506   \n",
       "1         {'C': 0.7, 'gamma': 0.5, 'kernel': 'linear'}  0.753247   0.650000   \n",
       "2    {'metric': 'euclidean', 'n_neighbors': 5, 'wei...  0.709957   0.592105   \n",
       "3    {'criterion': 'entropy', 'max_depth': 4, 'min_...  0.731602   0.600000   \n",
       "4    {'criterion': 'entropy', 'max_depth': 6, 'n_es...  0.774892   0.698630   \n",
       "..                                                 ...       ...        ...   \n",
       "115                                {'solver': 'lbfgs'}  0.791667   0.765432   \n",
       "116            {'C': 0.9, 'gamma': 1, 'kernel': 'rbf'}  0.798333   0.771084   \n",
       "117  {'metric': 'euclidean', 'n_neighbors': 6, 'wei...  0.971667   0.940909   \n",
       "118  {'criterion': 'gini', 'max_depth': 6, 'min_sam...  0.850000   0.764192   \n",
       "119  {'criterion': 'gini', 'max_depth': 6, 'n_estim...  0.885000   0.822727   \n",
       "\n",
       "       Recall  F1-score  \n",
       "0    0.641975  0.634146  \n",
       "1    0.641975  0.645963  \n",
       "2    0.555556  0.573248  \n",
       "3    0.703704  0.647727  \n",
       "4    0.629630  0.662338  \n",
       "..        ...       ...  \n",
       "115  0.587678  0.664879  \n",
       "116  0.606635  0.679045  \n",
       "117  0.981043  0.960557  \n",
       "118  0.829384  0.795455  \n",
       "119  0.857820  0.839907  \n",
       "\n",
       "[120 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter grids for each model\n",
    "\n",
    "# models = {\n",
    "#     'Logistic Regression': LogisticRegression(),\n",
    "#     'SVM': SVC(C=0.85, kernel='rbf', gamma=1),\n",
    "#     'KNN': KNeighborsClassifier(n_neighbors=4,weights='distance',metric='euclidean'),\n",
    "#     'Decision Tree': DecisionTreeClassifier(criterion='gini',max_depth=6),\n",
    "#     'Random Forest': RandomForestClassifier(criterion='gini',max_depth=4,n_estimators=50)\n",
    "# }\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        # 'C': [0.1, 1],\n",
    "        'solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.7, 0.8, 0.9],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': [0.5, 0.65,0.80 ,1]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [4, 5, 6],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [4, 5, 6],\n",
    "        'min_samples_split': [5, 6, 7]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 75],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [3, 4, 5, 6],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Prepare results storage\n",
    "results_list = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    X = dataset.drop('Outcome', axis=1)\n",
    "    y = dataset['Outcome']\n",
    "\n",
    "    for imputation_method in imputation_methods:\n",
    "        # Apply imputation\n",
    "        X_imputed = impute_data(imputation_method, X)\n",
    "\n",
    "        for scaling_method in scalers:\n",
    "            # Apply scaling\n",
    "            if scaling_method == 'standard':\n",
    "                scaler = StandardScaler()\n",
    "                X_scaled = scaler.fit_transform(X_imputed)\n",
    "            elif scaling_method == 'minmax':\n",
    "                scaler = MinMaxScaler()\n",
    "                X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                try:\n",
    "                    # Train-test split (70% training, 30% testing)\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "                    # GridSearchCV for hyperparameter tuning\n",
    "                    grid = GridSearchCV(model, param_grids[model_name], scoring='f1', cv=3)\n",
    "                    #  grid = GridSearchCV(model, param_grids[model_name], scoring='accuracy', cv=5, n_jobs=-1)\n",
    "                    grid.fit(X_train, y_train)\n",
    "                    best_model = grid.best_estimator_\n",
    "\n",
    "                    # Make predictions with the best model\n",
    "                    y_pred = best_model.predict(X_test)\n",
    "\n",
    "                    # Compute metrics\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "                    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "                    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "                    # Store the results\n",
    "                    results_list.append({\n",
    "                        'Dataset': dataset_name,\n",
    "                        'Imputation': imputation_method,\n",
    "                        'Scaling': scaling_method,\n",
    "                        'Model': model_name,\n",
    "                        'Best Params': grid.best_params_,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'Precision': precision,\n",
    "                        'Recall': recall,\n",
    "                        'F1-score': f1\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {dataset_name} with {imputation_method}, {scaling_method}, {model_name}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert results to DataFrame\n",
    "# results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "# results_df.to_csv('result_final_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pidd_data.iloc[:,:9]\n",
    "# X_imputed = impute_data('mean', X)\n",
    "# X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute_data(method, X):\n",
    "#     # Identify columns with 0 as missing values\n",
    "#     cols_with_zeros = X.columns[(X == 0).any().drop(column='Pregnancies')]\n",
    "#     X_imputed = X.copy()\n",
    "    \n",
    "#     for column in cols_with_zeros:\n",
    "#         missing_mask = X_imputed[column] == 0\n",
    "#         if method == 'mean':\n",
    "#             imputer = SimpleImputer(strategy='mean')\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'median':\n",
    "#             imputer = SimpleImputer(strategy='median')\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'knn':\n",
    "#             imputer = KNNImputer(n_neighbors=5)\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'random_sample':\n",
    "#             population = X_imputed[column][X_imputed[column] != 0]\n",
    "#             if not population.empty:\n",
    "#                 X_imputed.loc[missing_mask, column] = random.choices(population.tolist(), k=missing_mask.sum())\n",
    "#             else:\n",
    "#                 mean_value = X_imputed[column].mean()\n",
    "#                 X_imputed.loc[missing_mask, column] = mean_value\n",
    "#         elif method == 'mice':\n",
    "#             imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "    \n",
    "#     return X_imputed\n",
    "\n",
    "# def impute_data(method, X):\n",
    "#     # Identify columns with 0 as missing values, excluding 'Pregnancies'\n",
    "#     cols_with_zeros = X.columns[(X == 0).any()]\n",
    "#     cols_with_zeros = cols_with_zeros.drop('Pregnancies')  # Exclude 'Pregnancies'\n",
    "    \n",
    "#     X_imputed = X.copy()\n",
    "    \n",
    "#     for column in cols_with_zeros:\n",
    "#         missing_mask = X_imputed[column] == 0\n",
    "#         if method == 'mean':\n",
    "#             imputer = SimpleImputer(strategy='mean')\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'median':\n",
    "#             imputer = SimpleImputer(strategy='median')\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'knn':\n",
    "#             imputer = KNNImputer(n_neighbors=5)\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'random_sample':\n",
    "#             population = X_imputed[column][X_imputed[column] != 0]\n",
    "#             if not population.empty:\n",
    "#                 X_imputed.loc[missing_mask, column] = random.choices(population.tolist(), k=missing_mask.sum())\n",
    "#             else:\n",
    "#                 mean_value = X_imputed[column].mean()\n",
    "#                 X_imputed.loc[missing_mask, column] = mean_value\n",
    "#         elif method == 'mice':\n",
    "#             imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "    \n",
    "#     return X_imputed\n",
    "\n",
    "# def impute_data(method, X):\n",
    "#     # Identify columns with 0 as missing values, excluding 'Pregnancies'\n",
    "#     cols_with_zeros = X.columns[(X == 0).any()]\n",
    "#     cols_with_zeros = cols_with_zeros.drop('Pregnancies')  # Exclude 'Pregnancies'\n",
    "\n",
    "#     X_imputed = X.copy()\n",
    "    \n",
    "#     # Print initial state for reference\n",
    "#     print(f\"Imputation method: {method}\")\n",
    "#     print(f\"Columns to impute (0 values): {cols_with_zeros.tolist()}\")\n",
    "#     print(f\"Before imputation, number of 0s in columns to impute:\\n{(X_imputed[cols_with_zeros] == 0).sum()}\")\n",
    "\n",
    "#     for column in cols_with_zeros:\n",
    "#         missing_mask = X_imputed[column] == 0\n",
    "        \n",
    "#         if method == 'mean':\n",
    "#             imputer = SimpleImputer(strategy='mean')\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'median':\n",
    "#             imputer = SimpleImputer(strategy='median')\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'knn':\n",
    "#             imputer = KNNImputer(n_neighbors=5)\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "#         elif method == 'random_sample':\n",
    "#             population = X_imputed[column][X_imputed[column] != 0]\n",
    "#             if not population.empty:\n",
    "#                 X_imputed.loc[missing_mask, column] = random.choices(population.tolist(), k=missing_mask.sum())\n",
    "#             else:\n",
    "#                 mean_value = X_imputed[column].mean()\n",
    "#                 X_imputed.loc[missing_mask, column] = mean_value\n",
    "#         elif method == 'mice':\n",
    "#             imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "#             X_imputed[column] = imputer.fit_transform(X_imputed[column].values.reshape(-1, 1)).ravel()\n",
    "\n",
    "#     # Print the state after imputation for comparison\n",
    "#     print(f\"After imputation, number of 0s in columns to impute:\\n{(X_imputed[cols_with_zeros] == 0).sum()}\\n\")\n",
    "    \n",
    "#     return X_imputed\n",
    "\n",
    "# def impute_data(method, X):\n",
    "#     # Identify columns with 0 as missing values\n",
    "#     cols_with_zeros = X.columns[(X == 0).any()]\n",
    "#     cols_with_zeros = cols_with_zeros.drop('Pregnancies')  # Exclude 'Pregnancies'\n",
    "    \n",
    "#     # Convert 0 values to NaN for imputation\n",
    "#     X_imputed = X.copy()\n",
    "#     X_imputed[cols_with_zeros] = X_imputed[cols_with_zeros].replace(0, np.nan)\n",
    "    \n",
    "#     if method == 'mean':\n",
    "#         imputer = SimpleImputer(strategy='mean')\n",
    "#         X_imputed[cols_with_zeros] = imputer.fit_transform(X_imputed[cols_with_zeros])\n",
    "#     elif method == 'median':\n",
    "#         imputer = SimpleImputer(strategy='median')\n",
    "#         X_imputed[cols_with_zeros] = imputer.fit_transform(X_imputed[cols_with_zeros])\n",
    "#     elif method == 'knn':\n",
    "#         imputer = KNNImputer(n_neighbors=5)\n",
    "#         X_imputed[cols_with_zeros] = imputer.fit_transform(X_imputed[cols_with_zeros])\n",
    "#     elif method == 'random_sample':\n",
    "#         for column in cols_with_zeros:\n",
    "#             population = X_imputed[column][X_imputed[column] != 0]\n",
    "#             if not population.empty:\n",
    "#                 X_imputed.loc[X_imputed[column].isna(), column] = random.choices(population.tolist(), k=X_imputed[column].isna().sum())\n",
    "#             else:\n",
    "#                 mean_value = X_imputed[column].mean()\n",
    "#                 X_imputed.loc[X_imputed[column].isna(), column] = mean_value\n",
    "#     elif method == 'mice':\n",
    "#         imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "#         X_imputed[cols_with_zeros] = imputer.fit_transform(X_imputed[cols_with_zeros])\n",
    "    \n",
    "#     # Replace NaN back to 0 (if you want to keep consistency in the data)\n",
    "#     X_imputed[cols_with_zeros] = X_imputed[cols_with_zeros].fillna(0)\n",
    "    \n",
    "#     return X_imputed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
